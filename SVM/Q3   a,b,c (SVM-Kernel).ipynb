{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, LinearConstraint, Bounds\n",
    "import time\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
      "\n",
      "Data Set Information:\n",
      "\n",
      "Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.\n",
      "\n",
      "\n",
      "We use 4 attributions (the first 4 columns)\n",
      "\n",
      "1. variance of Wavelet Transformed image (continuous) \n",
      "2. skewness of Wavelet Transformed image (continuous) \n",
      "3. curtosis of Wavelet Transformed image (continuous) \n",
      "4. entropy of image (continuous) \n",
      "\n",
      "The label is the last column: genuine or forged\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "D = open ('bank-note//data-desc', 'r').read()\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = np.genfromtxt('bank-note/train.csv', delimiter=\",\")\n",
    "X_test = np.genfromtxt('bank-note/test.csv', delimiter=\",\")\n",
    "y_t = (2*X_t[:,-1] - 1).reshape(-1,1)\n",
    "y_test = (2*X_test[:,-1]-1).reshape(-1,1)\n",
    "# X_t[:,-1] = np.ones(train.shape[0])\n",
    "# X_test[:,-1] = np.ones(test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = X_t[:,:-1]\n",
    "X_test = X_test[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X_t[:, :]\n",
    "y = y_t[:, :]\n",
    "C_list = [100/873,500/873, 700/873]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = (Z*y) @ (Z*y).T\n",
    "f = lambda x: .5 * x.T @ T @ x - np.sum(x)\n",
    "eq_cons = {'type': 'eq',\n",
    "            'fun' : lambda x: x @ y,\n",
    "            'jac' : lambda x:  y.T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -3.997265783818733\n",
      "            Iterations: 11\n",
      "            Function evaluations: 9612\n",
      "            Gradient evaluations: 11\n",
      "27.5884952545166\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -13.919208660478832\n",
      "            Iterations: 16\n",
      "            Function evaluations: 13980\n",
      "            Gradient evaluations: 16\n",
      "38.644508838653564\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -18.25131630690838\n",
      "            Iterations: 16\n",
      "            Function evaluations: 13981\n",
      "            Gradient evaluations: 16\n",
      "37.7464656829834\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "x0 = np.zeros_like(y)\n",
    "for C in C_list:\n",
    "    start = time.time()\n",
    "    bounds = Bounds(np.zeros(y.shape[0]), C * np.ones(y.shape[0]))\n",
    "    res.append(minimize(f, x0, method='SLSQP',\n",
    "               constraints=[eq_cons], options={'ftol': 1e-5, 'disp': True},\n",
    "                bounds=bounds))\n",
    "    print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I = res[0].x>1e-5\n",
    "# w_star = (res[0].x[I]*y_t[I].reshape(-1,))@ X_t[I]\n",
    "# w_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# J = (res[0].x>1e-5)*(res[0].x<C_list[0] - 1e-5)\n",
    "# (y_t[J] - X_t[J]@w_star).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, run your dual SVM learning algorithm with   $C$ in $\\{\\frac{100}{873}, \\frac{500}{873}, \\frac{700}{873}\\}$. Recover the feature weights $\\mathbf{w}$ and the bias $b$. Compare with the parameters learned with stochastic sub-gradient descent in the primal domain (in Problem 2) and the same settings of $C$, what can you observe? What do you conclude and why? Note that if your code calculates the objective function with a double loop, the optimization can be quite slow. To accelerate, consider writing down the objective in terms of the matrix and vector operations, and treat the Lagrange multipliers that we want to optimize as a vector! Recall, we have discussed about it in our class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 100/873\n",
      "w_star = [-0.9439548  -0.64873703 -0.73091204 -0.03875256]\n",
      "\n",
      "\n",
      "C = 500/873\n",
      "w_star = [-1.56362227 -1.01464151 -1.18102452 -0.15710765]\n",
      "\n",
      "\n",
      "C = 700/873\n",
      "w_star = [-2.40987151 -1.4847     -0.94915911 -0.44544468]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = ['100/873','500/873', '700/873']\n",
    "for j in range(3):\n",
    "    print('C = {}'.format(C[j]))\n",
    "    I = res[0].x > 1e-5\n",
    "    w_star = (res[j].x[I]*y_t[I].reshape(-1,))@ X_t[I]\n",
    "    J = (res[j].x>1e-8)*(res[j].x<C_list[j] - 1e-2)\n",
    "    print('w_star = {}'.format(w_star))\n",
    "#     print('b_star = {}'.format((y_t[J] - X_t[J]@w_star).mean()))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, alps, Vecs, lbls, C1):\n",
    "    \n",
    "    beta = list(np.where(C1 - alps  > 1e-5)[0])\n",
    "#     print(len(beta))\n",
    "    b = (sum(lbls[beta]) - np.sum(Vecs[beta,:] @ (alps * lbls * Vecs).T))/len(beta)\n",
    "    print('b_star = {}'.format(b))\n",
    "\n",
    "    return np.where(np.sum(X @ (alps * lbls * Vecs).T, 1) + b  > 0 ,1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 100/873\n",
      "numebr of support vectors = 45\n",
      "b_star = [1.40157651]\n",
      "Train Error for C =100/873 is 0.011467889908256881\n",
      "b_star = [1.40157651]\n",
      "Test Error for C =100/873 is 0.012\n",
      "\n",
      "\n",
      "C = 500/873\n",
      "numebr of support vectors = 31\n",
      "b_star = [1.82395047]\n",
      "Train Error for C =500/873 is 0.008027522935779817\n",
      "b_star = [1.82395047]\n",
      "Test Error for C =500/873 is 0.008\n",
      "\n",
      "\n",
      "C = 700/873\n",
      "numebr of support vectors = 31\n",
      "b_star = [2.04295877]\n",
      "Train Error for C =700/873 is 0.009174311926605505\n",
      "b_star = [2.04295877]\n",
      "Test Error for C =700/873 is 0.01\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print ('C = {}'.format(C[i]))\n",
    "    Sup_inds = list(np.where(res[i].x > 1e-5)[0])\n",
    "    print('numebr of support vectors = {}'.format(len(Sup_inds)))\n",
    "    Sup_alps = res[i].x[Sup_inds].reshape(-1,1)\n",
    "    Sup_Vecs = Z[Sup_inds,:]\n",
    "    Sup_lbls = y[Sup_inds]\n",
    "    P_t = predict(X_t, Sup_alps, Sup_Vecs, Sup_lbls, C_list[i]).reshape(-1,1)\n",
    "    print('Train Error for C ={} is {}'.format(C[i],  np.sum(P_t * y_t < 0)/y_t.shape[0]))\n",
    "    P = predict(X_test, Sup_alps, Sup_Vecs, Sup_lbls, C_list[i]).reshape(-1,1)\n",
    "    print('Test Error for C ={} is {}'.format(C[i],  np.sum(P * y_test < 0)/y_test.shape[0]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Kernel Trick \"Gaussian kernel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = X_t[:, :]\n",
    "y2 = y_t[:, :]\n",
    "C_list = [100/873,500/873, 700/873]\n",
    "gamma_list = [0.1, 0.5, 1, 5, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_k(A, B, gamma):  #Resturn a matrix whose ijth entry is exp{-||A_i-B_j||**2/gamma}\n",
    "    temp = np.sum(A * A, 1).reshape(A.shape[0], 1) + np.sum(B * B, 1).reshape(1, B.shape[0]) - 2 * A @ B.T\n",
    "    return np.exp(-temp/gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(872, 872)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -82.72279551034315\n",
      "            Iterations: 23\n",
      "            Function evaluations: 20081\n",
      "            Gradient evaluations: 23\n",
      "spent time for (C, gamma) = (0.1145475372279496, 0.1) is 52.25137281417847\n",
      "---------------------------------------------------------\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -285.8328149287465\n",
      "            Iterations: 28\n",
      "            Function evaluations: 24447\n",
      "            Gradient evaluations: 28\n",
      "spent time for (C, gamma) = (0.572737686139748, 0.1) is 61.514962911605835\n",
      "---------------------------------------------------------\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -317.8535980255414\n",
      "            Iterations: 37\n",
      "            Function evaluations: 32304\n",
      "            Gradient evaluations: 37\n",
      "spent time for (C, gamma) = (0.8018327605956472, 0.1) is 68.7200858592987\n",
      "---------------------------------------------------------\n",
      "(872, 872)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py:282: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  warnings.warn(\"Values in x were outside bounds during a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -74.16552071256318\n",
      "            Iterations: 35\n",
      "            Function evaluations: 30560\n",
      "            Gradient evaluations: 35\n",
      "spent time for (C, gamma) = (0.1145475372279496, 0.5) is 81.33784174919128\n",
      "---------------------------------------------------------\n",
      "Iteration limit reached    (Exit mode 9)\n",
      "            Current function value: -159.75506486932795\n",
      "            Iterations: 100\n",
      "            Function evaluations: 87305\n",
      "            Gradient evaluations: 100\n",
      "spent time for (C, gamma) = (0.572737686139748, 0.5) is 209.27870321273804\n",
      "---------------------------------------------------------\n",
      "Iteration limit reached    (Exit mode 9)\n",
      "            Current function value: -164.36302839521855\n",
      "            Iterations: 100\n",
      "            Function evaluations: 87305\n",
      "            Gradient evaluations: 100\n",
      "spent time for (C, gamma) = (0.8018327605956472, 0.5) is 177.19026899337769\n",
      "---------------------------------------------------------\n",
      "(872, 872)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -63.414534689569926\n",
      "            Iterations: 42\n",
      "            Function evaluations: 36670\n",
      "            Gradient evaluations: 42\n",
      "spent time for (C, gamma) = (0.1145475372279496, 1) is 97.71346306800842\n",
      "---------------------------------------------------------\n",
      "Iteration limit reached    (Exit mode 9)\n",
      "            Current function value: -102.93935672601873\n",
      "            Iterations: 100\n",
      "            Function evaluations: 87307\n",
      "            Gradient evaluations: 100\n",
      "spent time for (C, gamma) = (0.572737686139748, 1) is 205.78671288490295\n",
      "---------------------------------------------------------\n",
      "Iteration limit reached    (Exit mode 9)\n",
      "            Current function value: -104.21470031098767\n",
      "            Iterations: 100\n",
      "            Function evaluations: 87309\n",
      "            Gradient evaluations: 100\n",
      "spent time for (C, gamma) = (0.8018327605956472, 1) is 197.3166961669922\n",
      "---------------------------------------------------------\n",
      "(872, 872)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -26.45826704910047\n",
      "            Iterations: 53\n",
      "            Function evaluations: 46278\n",
      "            Gradient evaluations: 53\n",
      "spent time for (C, gamma) = (0.1145475372279496, 5) is 124.33664393424988\n",
      "---------------------------------------------------------\n",
      "Iteration limit reached    (Exit mode 9)\n",
      "            Current function value: -33.227989861407636\n",
      "            Iterations: 100\n",
      "            Function evaluations: 87310\n",
      "            Gradient evaluations: 100\n",
      "spent time for (C, gamma) = (0.572737686139748, 5) is 225.5380880832672\n",
      "---------------------------------------------------------\n",
      "Iteration limit reached    (Exit mode 9)\n",
      "            Current function value: -33.788354468548675\n",
      "            Iterations: 100\n",
      "            Function evaluations: 87312\n",
      "            Gradient evaluations: 100\n",
      "spent time for (C, gamma) = (0.8018327605956472, 5) is 226.64598608016968\n",
      "---------------------------------------------------------\n",
      "(872, 872)\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -20.289240081578626\n",
      "            Iterations: 57\n",
      "            Function evaluations: 49765\n",
      "            Gradient evaluations: 57\n",
      "spent time for (C, gamma) = (0.1145475372279496, 100) is 134.50223684310913\n",
      "---------------------------------------------------------\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -39.830173140740065\n",
      "            Iterations: 61\n",
      "            Function evaluations: 53261\n",
      "            Gradient evaluations: 61\n",
      "spent time for (C, gamma) = (0.572737686139748, 100) is 143.37884306907654\n",
      "---------------------------------------------------------\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -46.02606342394454\n",
      "            Iterations: 80\n",
      "            Function evaluations: 69848\n",
      "            Gradient evaluations: 80\n",
      "spent time for (C, gamma) = (0.8018327605956472, 100) is 191.23446989059448\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "res_K = {}\n",
    "x0 = np.zeros_like(y2)\n",
    "\n",
    "for i in range(len(gamma_list)):\n",
    "\n",
    "    \n",
    "    \n",
    "    K1 = y2 * G_k(Z2, Z2, gamma_list[i]) * y2.T\n",
    "    print(K1.shape)\n",
    "    f = lambda x: .5 * x.T @ K1 @ x - np.sum(x)\n",
    "    eq_cons = {'type': 'eq',\n",
    "                'fun' : lambda x: x @ y2,\n",
    "                'jac' : lambda x:  y2.T}\n",
    "    \n",
    "    for j in range(len(C_list)):\n",
    "        \n",
    "        start = time.time()\n",
    "        bounds = Bounds(np.zeros(y2.shape[0]), C_list[j] * np.ones(y2.shape[0]))\n",
    "        res_K[(j, i)] = minimize(f, x0, method='SLSQP',\n",
    "                   constraints=[eq_cons], options={'ftol': 1e-9, 'disp': True},\n",
    "                    bounds=bounds)\n",
    "        \n",
    "        print('spent time for (C, gamma) = {} is'.format((C_list[j], gamma_list[i])), time.time() - start)\n",
    "        print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_l_str = ['100/873', '500/873', '700/873']\n",
    "gamma_l_str = ['0.1', '0.5', '1', '5', '100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_K(X, alps, Vecs, lbls, gamma, C, i, j):\n",
    "    \n",
    "    beta = list(np.where(alps < C - 1e-9)[0])   \n",
    "    Beta[(j,i)] = beta\n",
    "#     print('numebr of support vectors = {}'.format(len(beta)))\n",
    "        \n",
    "    if len(beta)>0:\n",
    "        \n",
    "        k = np.argmin(alps[beta])\n",
    "        \n",
    "        X_j = Vecs[beta[k]].reshape(1,-1)\n",
    "        H = Vecs\n",
    "\n",
    "        N = np.sum(X_j * X_j, 1).reshape(-1,1) + np.sum(H * H, 1).reshape(-1,1) - 2 * H @ X_j.T\n",
    "        M = lbls * alps * np.exp(- N/gamma)\n",
    "        b = lbls[beta[k]] - np.sum(M)\n",
    "        \n",
    "#         print('b=', b)\n",
    "    else:\n",
    "        b =0\n",
    "#         print('b=', 0)\n",
    "        \n",
    "    temp2 = G_k(X , Vecs, gamma) * (alps * lbls).T\n",
    "\n",
    "    return np.where(np.sum(temp2, 1) + b > 0 , 1, -1) , np.where(np.sum(temp2, 1) > 0 , 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$-------------------------------$\\\\ \n",
      "$C = 100/873, \\gamma = 0.1$\\\\\n",
      "\\#support vectors = 869\\\\\n",
      "Test Error for $(C, \\gamma) =('100/873', '0.1')$ is 0.442\\\\\n",
      "Train Error for $(C, \\gamma) =('100/873', '0.1')$ is 0.4461009174311927\\\\\n",
      "\\#overlapped support vectors between values of $\\gamma_0, \\gamma_1 = 825$\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 100/873, \\gamma = 0.5$\\\\\n",
      "\\#support vectors = 825\\\\\n",
      "Test Error for $(C, \\gamma) =('100/873', '0.5')$ is 0.426\\\\\n",
      "Train Error for $(C, \\gamma) =('100/873', '0.5')$ is 0.40711009174311924\\\\\n",
      "\\#overlapped support vectors between values of $\\gamma_1, \\gamma_2 = 799$\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 100/873, \\gamma = 1$\\\\\n",
      "\\#support vectors = 805\\\\\n",
      "Test Error for $(C, \\gamma) =('100/873', '1')$ is 0.192\\\\\n",
      "Train Error for $(C, \\gamma) =('100/873', '1')$ is 0.09518348623853211\\\\\n",
      "\\#overlapped support vectors between values of $\\gamma_2, \\gamma_3 = 442$\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 100/873, \\gamma = 5$\\\\\n",
      "\\#support vectors = 442\\\\\n",
      "Test Error for $(C, \\gamma) =('100/873', '5')$ is 0.004\\\\\n",
      "Train Error for $(C, \\gamma) =('100/873', '5')$ is 0.0034403669724770644\\\\\n",
      "\\#overlapped support vectors between values of $\\gamma_3, \\gamma_4 = 217$\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 100/873, \\gamma = 100$\\\\\n",
      "\\#support vectors = 290\\\\\n",
      "Test Error for $(C, \\gamma) =('100/873', '100')$ is 0.014\\\\\n",
      "Train Error for $(C, \\gamma) =('100/873', '100')$ is 0.016055045871559634\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 500/873, \\gamma = 0.1$\\\\\n",
      "\\#support vectors = 869\\\\\n",
      "Test Error for $(C, \\gamma) =('500/873', '0.1')$ is 0.348\\\\\n",
      "Train Error for $(C, \\gamma) =('500/873', '0.1')$ is 0.0\\\\\n",
      "\\#overlapped support vectors between values of $\\gamma_0, \\gamma_1 = 731$\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 500/873, \\gamma = 0.5$\\\\\n",
      "\\#support vectors = 731\\\\\n",
      "Test Error for $(C, \\gamma) =('500/873', '0.5')$ is 0.018\\\\\n",
      "Train Error for $(C, \\gamma) =('500/873', '0.5')$ is 0.0\\\\\n",
      "\\#overlapped support vectors between values of $\\gamma_1, \\gamma_2 = 553$\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 500/873, \\gamma = 1$\\\\\n",
      "\\#support vectors = 555\\\\\n",
      "Test Error for $(C, \\gamma) =('500/873', '1')$ is 0.004\\\\\n",
      "Train Error for $(C, \\gamma) =('500/873', '1')$ is 0.0\\\\\n",
      "\\#overlapped support vectors between values of $\\gamma_2, \\gamma_3 = 198$\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 500/873, \\gamma = 5$\\\\\n",
      "\\#support vectors = 208\\\\\n",
      "Test Error for $(C, \\gamma) =('500/873', '5')$ is 0.0\\\\\n",
      "Train Error for $(C, \\gamma) =('500/873', '5')$ is 0.0\\\\\n",
      "\\#overlapped support vectors between values of $\\gamma_3, \\gamma_4 = 73$\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 500/873, \\gamma = 100$\\\\\n",
      "\\#support vectors = 116\\\\\n",
      "Test Error for $(C, \\gamma) =('500/873', '100')$ is 0.006\\\\\n",
      "Train Error for $(C, \\gamma) =('500/873', '100')$ is 0.008027522935779817\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 700/873, \\gamma = 0.1$\\\\\n",
      "\\#support vectors = 868\\\\\n",
      "Test Error for $(C, \\gamma) =('700/873', '0.1')$ is 0.232\\\\\n",
      "Train Error for $(C, \\gamma) =('700/873', '0.1')$ is 0.0\\\\\n",
      "\\#overlapped support vectors between values of $\\gamma_0, \\gamma_1 = 693$\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 700/873, \\gamma = 0.5$\\\\\n",
      "\\#support vectors = 693\\\\\n",
      "Test Error for $(C, \\gamma) =('700/873', '0.5')$ is 0.01\\\\\n",
      "Train Error for $(C, \\gamma) =('700/873', '0.5')$ is 0.0\\\\\n",
      "\\#overlapped support vectors between values of $\\gamma_1, \\gamma_2 = 524$\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 700/873, \\gamma = 1$\\\\\n",
      "\\#support vectors = 527\\\\\n",
      "Test Error for $(C, \\gamma) =('700/873', '1')$ is 0.004\\\\\n",
      "Train Error for $(C, \\gamma) =('700/873', '1')$ is 0.0\\\\\n",
      "\\#overlapped support vectors between values of $\\gamma_2, \\gamma_3 = 186$\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 700/873, \\gamma = 5$\\\\\n",
      "\\#support vectors = 194\\\\\n",
      "Test Error for $(C, \\gamma) =('700/873', '5')$ is 0.0\\\\\n",
      "Train Error for $(C, \\gamma) =('700/873', '5')$ is 0.0\\\\\n",
      "\\#overlapped support vectors between values of $\\gamma_3, \\gamma_4 = 65$\\\\\n",
      "$-------------------------------$\\\\ \n",
      "$C = 700/873, \\gamma = 100$\\\\\n",
      "\\#support vectors = 98\\\\\n",
      "Test Error for $(C, \\gamma) =('700/873', '100')$ is 0.004\\\\\n",
      "Train Error for $(C, \\gamma) =('700/873', '100')$ is 0.0034403669724770644\\\\\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(C_list)):\n",
    "    for i in range(len(gamma_list)):\n",
    "        \n",
    "        print (\"$-------------------------------$\\\\\\ \")\n",
    "        print('$C = {}, \\gamma = {}$\\\\\\\\'.format(C_l_str[j], gamma_l_str[i]))\n",
    "\n",
    "    \n",
    "#         Sup_inds = list(np.where(res_K[(j,i)].x > 1e-9)[0])\n",
    "        Sup_inds = (res_K[(j,i)].x > 1e-9)\n",
    "        print('\\#support vectors = {}\\\\\\\\'.format(Sup_inds.sum()))\n",
    "#         print('#support vectors = {}'.format(len(Sup_inds)))\n",
    "        \n",
    "        Sup_alps = res_K[(j,i)].x[Sup_inds].reshape(-1,1)\n",
    "        Sup_Vecs = Z2[Sup_inds, :]\n",
    "        Sup_lbls = y2[Sup_inds, :]\n",
    "        P = predict_K(X_test, Sup_alps, Sup_Vecs, Sup_lbls, gamma_list[i], C_list[j], i, j)\n",
    "        P_0 = P[0].reshape(-1,1)\n",
    "#         P_1 = P[1].reshape(-1,1)\n",
    "#         print('(i,j) =', (j,i))\n",
    "        print('Test Error for $(C, \\gamma) ={}$ is {}\\\\\\\\'.format((C_l_str[j], gamma_l_str[i]), \n",
    "                                                            np.sum(P_0 * y_test < 0)/y_test.shape[0]))\n",
    "        \n",
    "        \n",
    "        P = predict_K(X_t, Sup_alps, Sup_Vecs, Sup_lbls, gamma_list[i], C_list[j], i, j)\n",
    "        P_0 = P[0].reshape(-1,1)\n",
    "#         P_1 = P[1].reshape(-1,1)\n",
    "        print('Train Error for $(C, \\gamma) ={}$ is {}\\\\\\\\'.format((C_l_str[j], gamma_l_str[i]), \n",
    "                                                            np.sum(P_0 * y_t < 0)/y_t.shape[0]))\n",
    "        \n",
    "#         print(colored('With no b = ', 'red'),  \n",
    "#               colored(100 * np.sum(P_1 * y_test < 0)/y_test.shape[0], 'red'))\n",
    "        if i < len(gamma_list)-1:\n",
    "            temp = (res_K[(j,i)].x > 1e-9) * (res_K[(j,i+1)].x > 1e-9)\n",
    "#             print(temp)\n",
    "            print('\\#overlapped support vectors between values of $\\gamma_{}, \\gamma_{} = {}$\\\\\\\\'.format(\n",
    "                i , i+1, temp.sum()))\n",
    "        #print(colored('Clusters for are:', 'blue'))\n",
    "#         print (\"----------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
